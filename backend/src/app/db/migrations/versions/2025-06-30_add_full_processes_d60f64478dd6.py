# type: ignore
"""Add full processes

Revision ID: d60f64478dd6
Revises: 041c77a5f1fe
Create Date: 2025-06-30 15:47:23.936258

"""

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from advanced_alchemy.types import (
    GUID,
    ORA_JSONB,
    DateTimeUTC,
    EncryptedString,
    EncryptedText,
)
from alembic import op
from sqlalchemy import Text  # noqa: F401
from sqlalchemy.dialects import postgresql

if TYPE_CHECKING:
    pass

__all__ = [
    "downgrade",
    "upgrade",
    "schema_upgrades",
    "schema_downgrades",
    "data_upgrades",
    "data_downgrades",
]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText

# revision identifiers, used by Alembic.
revision = "d60f64478dd6"
down_revision = "041c77a5f1fe"
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()


def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()


def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "process_category",
        sa.Column("id", sa.GUID(length=16), nullable=False),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("sa_orm_sentinel", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTimeUTC(timezone=True), nullable=False),
        sa.Column("updated_at", sa.DateTimeUTC(timezone=True), nullable=False),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_process_category")),
    )
    op.create_table(
        "process_process_category",
        sa.Column("process_id", sa.GUID(length=16), nullable=False),
        sa.Column("process_category_id", sa.GUID(length=16), nullable=False),
        sa.ForeignKeyConstraint(
            ["process_category_id"],
            ["process_category.id"],
            name=op.f(
                "fk_process_process_category_process_category_id_process_category"
            ),
            ondelete="CASCADE",
        ),
        sa.ForeignKeyConstraint(
            ["process_id"],
            ["process.id"],
            name=op.f("fk_process_process_category_process_id_process"),
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint(
            "process_id",
            "process_category_id",
            name=op.f("pk_process_process_category"),
        ),
    )
    with op.batch_alter_table("process", schema=None) as batch_op:
        batch_op.add_column(sa.Column("density", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("display_name", sa.String(), nullable=True))
        batch_op.add_column(sa.Column("elec_mj", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("heat_mj", sa.Float(), nullable=False))
        batch_op.add_column(
            sa.Column(
                "scopes",
                postgresql.ARRAY(
                    sa.Enum("food", "object", "textile", "veli", name="scope"),
                    dimensions=1,
                ),
                nullable=False,
            )
        )
        batch_op.add_column(sa.Column("source", sa.String(), nullable=False))
        batch_op.add_column(sa.Column("source_id", sa.String(), nullable=False))
        unit = postgresql.ENUM(
            "Item(s)", "kg", "kWh", "L", "m2", "m3", "MJ", "t⋅km", name="unit"
        )
        unit.create(batch_op.get_bind())
        batch_op.add_column(
            sa.Column(
                "unit",
                sa.Enum(
                    "Item(s)", "kg", "kWh", "L", "m2", "m3", "MJ", "t⋅km", name="unit"
                ),
                nullable=False,
            )
        )
        batch_op.add_column(sa.Column("waste", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("acd", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("cch", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("etf", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("etf-c", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("fru", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("fwe", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("htc", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("htc-c", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("htn", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("htn-c", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("ior", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("ldu", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("mru", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("ozd", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("pco", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("pma", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("swe", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("tre", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("wtu", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("ecs", sa.Float(), nullable=False))
        batch_op.add_column(sa.Column("pef", sa.Float(), nullable=False))
        batch_op.drop_column("display")
        batch_op.drop_column("name")

    # ### end Alembic commands ###


def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("process", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False)
        )
        batch_op.add_column(
            sa.Column("display", sa.VARCHAR(), autoincrement=False, nullable=True)
        )
        batch_op.drop_column("pef")
        batch_op.drop_column("ecs")
        batch_op.drop_column("wtu")
        batch_op.drop_column("tre")
        batch_op.drop_column("swe")
        batch_op.drop_column("pma")
        batch_op.drop_column("pco")
        batch_op.drop_column("ozd")
        batch_op.drop_column("mru")
        batch_op.drop_column("ldu")
        batch_op.drop_column("ior")
        batch_op.drop_column("htn-c")
        batch_op.drop_column("htn")
        batch_op.drop_column("htc-c")
        batch_op.drop_column("htc")
        batch_op.drop_column("fwe")
        batch_op.drop_column("fru")
        batch_op.drop_column("etf-c")
        batch_op.drop_column("etf")
        batch_op.drop_column("cch")
        batch_op.drop_column("acd")
        batch_op.drop_column("waste")
        batch_op.drop_column("unit")
        batch_op.drop_column("source_id")
        batch_op.drop_column("source")
        batch_op.drop_column("scopes")
        batch_op.drop_column("heat_mj")
        batch_op.drop_column("elec_mj")
        batch_op.drop_column("display_name")
        batch_op.drop_column("density")

    sa.Enum(name="unit").drop(op.get_bind(), checkfirst=False)

    op.drop_table("process_process_category")
    op.drop_table("process_category")
    # ### end Alembic commands ###


def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""


def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""
